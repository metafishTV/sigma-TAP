# TAPS Stage 1 Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Build a post-hoc TAPS/RIP diagnostic overlay that computes mode scores from metathetic ensemble trajectories, tests mode independence via correlation analysis, compares gated vs ungated runs, and fixes the Jaccard near-stasis edge case.

**Architecture:** New `simulator/taps.py` module with pure functions that take a trajectory (list of snapshot dicts) and return per-step TAPS/RIP mode scores. New `scripts/taps_diagnostics.py` CLI script for running diagnostics and generating figures. Fix to `simulator/metathetic.py` for deep-stasis behavior when no Jaccard neighbor exists. All TAPS computation is post-hoc (reads completed trajectories, no changes to run loop).

**Tech Stack:** Python 3.12, numpy, matplotlib, unittest. Python executable: `C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe`. Repo: `C:\Users\user\Documents\New folder\sigma-TAP-repo`.

---

### Task 1: Jaccard near-stasis fix

**Files:**
- Modify: `simulator/metathetic.py:54-55` (add `_deep_stasis` field to MetatheticAgent)
- Modify: `simulator/metathetic.py:675-694` (rewrite total_w == 0 branch in `_check_disintegration_redistribution`)
- Test: `tests/test_metathetic.py`

**Context:**
Currently when no Jaccard neighbor exists (total_w == 0), the agent's types and knowledge are completely lost and it's marked dissolved. The fix retains types and a 5% knowledge residual, marking the agent as deep stasis instead. This represents a rogue-planet state: frozen but structurally intact.

**Step 1: Write failing tests**

Add to `tests/test_metathetic.py` in the `TestDisintegrationRedistribution` class:

```python
    def test_deep_stasis_retains_types(self):
        """Agent with no Jaccard neighbor enters deep stasis, retains types."""
        from simulator.metathetic import MetatheticEnsemble
        ens = MetatheticEnsemble(
            n_agents=3, initial_M=10.0,
            alpha=5e-3, a=3.0, mu=0.005,
            variant="logistic", carrying_capacity=2e5,
            seed=42,
        )
        # Agent 0: unique types, no overlap with anyone
        ens.agents[0].active = False
        ens.agents[0]._dormant_steps = 30
        ens.agents[0].type_set = {999, 998}
        ens.agents[0].k = 100.0
        # Agents 1,2: share types with each other but NOT with agent 0
        ens.agents[1].type_set = {0, 1}
        ens.agents[2].type_set = {0, 2}

        ens._check_disintegration_redistribution()

        # Agent should be in deep stasis, not dissolved
        self.assertTrue(ens.agents[0]._deep_stasis)
        self.assertFalse(ens.agents[0]._dissolved)
        # Types preserved
        self.assertEqual(ens.agents[0].type_set, {999, 998})
        # Knowledge truncated to 5% residual
        self.assertAlmostEqual(ens.agents[0].k, 5.0, places=1)
        # k_lost tracks the truncated portion
        self.assertAlmostEqual(ens.k_lost, 95.0, places=1)
        # n_types_lost is 0 (types preserved)
        self.assertEqual(ens.n_types_lost, 0)

    def test_deep_stasis_not_redisintegrated(self):
        """Deep stasis agent should not be processed again."""
        from simulator.metathetic import MetatheticEnsemble
        ens = MetatheticEnsemble(
            n_agents=3, initial_M=10.0,
            alpha=5e-3, a=3.0, mu=0.005,
            variant="logistic", carrying_capacity=2e5,
            seed=42,
        )
        ens.agents[0].active = False
        ens.agents[0]._dormant_steps = 30
        ens.agents[0].type_set = {999}
        ens.agents[0].k = 100.0
        ens.agents[1].type_set = {0, 1}
        ens.agents[2].type_set = {0, 2}

        ens._check_disintegration_redistribution()
        first_k = ens.agents[0].k
        first_lost = ens.k_lost

        # Second call should be a no-op
        ens._check_disintegration_redistribution()
        self.assertEqual(ens.agents[0].k, first_k)
        self.assertEqual(ens.k_lost, first_lost)
        self.assertEqual(ens.n_disintegration_redistributions, 1)
```

**Step 2: Run tests to verify they fail**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/test_metathetic.py::TestDisintegrationRedistribution::test_deep_stasis_retains_types tests/test_metathetic.py::TestDisintegrationRedistribution::test_deep_stasis_not_redisintegrated -v`
Expected: FAIL (AttributeError for `_deep_stasis`)

**Step 3: Implement**

In `simulator/metathetic.py`:

1. Add `_deep_stasis` field to MetatheticAgent (after `_dissolved` on line 55):
```python
    _deep_stasis: bool = field(default=False, init=False, repr=False)
```

2. Add `_deep_stasis` to the skip condition in `_check_disintegration_redistribution` (line 659):
```python
            if agent._dissolved or agent._deep_stasis or agent.active:
                continue
```

3. Replace the `total_w == 0` branch (lines 675-678) with:
```python
            if total_w == 0:
                # No interactive neighbor — enter deep stasis (rogue planet).
                # Types preserved (identity intact), knowledge truncated to
                # 5% residual. Agent can potentially reactivate if cross-
                # metathesis introduces shared types from a passing agent.
                residual_fraction = 0.05
                k_residual = agent.k * residual_fraction
                self.k_lost += agent.k - k_residual
                # n_types_lost stays 0: types are preserved
                agent.k = k_residual
                agent._deep_stasis = True
                self.n_disintegration_redistributions += 1
                continue  # skip the dissolved cleanup below
```

4. Move the dissolved cleanup into an `else` clause or after the `continue` so it only runs for the redistribution path. The full rewritten loop body after the Jaccard computation becomes:
```python
            if total_w == 0:
                # No interactive neighbor — enter deep stasis
                residual_fraction = 0.05
                k_residual = agent.k * residual_fraction
                self.k_lost += agent.k - k_residual
                agent.k = k_residual
                agent._deep_stasis = True
                self.n_disintegration_redistributions += 1
                continue

            # Redistribute types to highest-weight agent
            agent_by_id = {a.agent_id: a for a in active}
            sorted_recipients = sorted(weights.keys(), key=lambda aid: (-weights[aid], aid))
            best_recipient = agent_by_id[sorted_recipients[0]]
            best_recipient.type_set = best_recipient.type_set | agent.type_set

            # Redistribute knowledge proportionally
            for aid, w in weights.items():
                fraction = w / total_w
                agent_by_id[aid].k += agent.k * fraction

            agent.type_set = set()
            agent.k = 0.0
            agent._dissolved = True
            self.n_disintegration_redistributions += 1
```

**Step 4: Run tests**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/test_metathetic.py -v`
Expected: All pass including the 2 new tests.

**Step 5: Run full suite**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/ -v`
Expected: 176/176 pass (174 existing + 2 new).

**Step 6: Commit**

```bash
git add simulator/metathetic.py tests/test_metathetic.py
git commit -m "fix: deep stasis for isolated agents instead of total knowledge loss

When no Jaccard neighbor exists during disintegration, retain types and
5% knowledge residual. Agent enters deep stasis (frozen but structurally
intact) rather than being dissolved with total loss.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

### Task 2: Core TAPS computation module

**Files:**
- Create: `simulator/taps.py`
- Test: `tests/test_taps.py`

**Context:**
Pure-function module computing TAPS/RIP mode scores post-hoc from trajectory data. Each function takes a trajectory (list of snapshot dicts from `MetatheticEnsemble.run()`) and returns per-step score arrays. The module has no coupling to the simulation engine — it only reads dicts.

Snapshot fields available per step: `step`, `D_total`, `k_total`, `total_M`, `n_active`, `n_dormant`, `agent_k_list`, `convergence`, `texture_type`, `a_env`, `K_env`, `innovation_potential`, `n_self_metatheses` (cumulative), `n_absorptive_cross` (cumulative), `n_novel_cross` (cumulative), `n_env_transitions` (cumulative), `n_disintegration_redistributions` (cumulative), `n_types_lost` (cumulative), `k_lost` (cumulative), `affordance_mean`, `temporal_state_counts`.

**Step 1: Write failing tests**

Create `tests/test_taps.py`:

```python
"""Tests for TAPS/RIP diagnostic overlay."""
import os
import sys
import unittest

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))


def _make_trajectory(steps=10, with_events=True):
    """Build a synthetic trajectory for testing.

    Creates a trajectory where events happen at specific steps so test
    assertions are deterministic.
    """
    traj = []
    cumul = {"self": 0, "absorptive": 0, "novel": 0, "env": 0, "disint": 0,
             "types_lost": 0, "k_lost": 0.0}
    for t in range(steps):
        if with_events and t == 3:
            cumul["self"] += 1
            cumul["absorptive"] += 1
        if with_events and t == 6:
            cumul["novel"] += 1
            cumul["disint"] += 1
        traj.append({
            "step": t,
            "D_total": 10 + t,
            "k_total": 50.0 + t * 5,
            "total_M": 100.0 + t * 10,
            "n_active": 8,
            "n_dormant": 2,
            "agent_k_list": [10.0] * 8,
            "convergence": 0.5,
            "texture_type": 1,
            "a_env": 3.0,
            "K_env": 2e5,
            "innovation_potential": 0.8 - t * 0.01,
            "n_self_metatheses": cumul["self"],
            "n_absorptive_cross": cumul["absorptive"],
            "n_novel_cross": cumul["novel"],
            "n_env_transitions": cumul["env"],
            "n_disintegration_redistributions": cumul["disint"],
            "n_types_lost": cumul["types_lost"],
            "k_lost": cumul["k_lost"],
            "affordance_mean": 0.6,
            "temporal_state_counts": {0: 0, 1: 2, 2: 3, 3: 3, 4: 2},
        })
    return traj


class TestTransvolution(unittest.TestCase):
    """Tests for T mode (involution/evolution/condensation)."""

    def test_involution_includes_self_and_absorptive(self):
        """Involution score should count self + absorptive events."""
        from simulator.taps import compute_transvolution
        traj = _make_trajectory(steps=10)
        result = compute_transvolution(traj)
        # At step 3: delta_self=1, delta_absorptive=1, total_events=2
        # involution = (1+1)/2 = 1.0
        self.assertAlmostEqual(result["involution"][3], 1.0)

    def test_evolution_includes_novel_and_disintegration(self):
        """Evolution score should count novel + disintegration events."""
        from simulator.taps import compute_transvolution
        traj = _make_trajectory(steps=10)
        result = compute_transvolution(traj)
        # At step 6: delta_novel=1, delta_disint=1, total_events=2
        # evolution = (1+1)/2 = 1.0
        self.assertAlmostEqual(result["evolution"][6], 1.0)

    def test_condensation_is_product(self):
        """Condensation = involution * evolution."""
        from simulator.taps import compute_transvolution
        traj = _make_trajectory(steps=10)
        result = compute_transvolution(traj)
        for t in range(len(result["condensation"])):
            self.assertAlmostEqual(
                result["condensation"][t],
                result["involution"][t] * result["evolution"][t],
            )


class TestAnopression(unittest.TestCase):
    """Tests for A mode (pressure decomposition)."""

    def test_anopressive_sums_to_one(self):
        """Anopressive scores (expression+impression+adpression) should sum to 1."""
        from simulator.taps import compute_anopression
        traj = _make_trajectory(steps=10)
        result = compute_anopression(traj, mu=0.005)
        for t in range(len(result["expression"])):
            ano_total = (result["expression"][t]
                         + result["impression"][t]
                         + result["adpression"][t])
            if ano_total > 0:  # only when events happen
                self.assertAlmostEqual(ano_total, 1.0, places=5)

    def test_anapressive_can_exceed_one(self):
        """Anapressive total can exceed 1.0 (net entropy)."""
        from simulator.taps import compute_anopression
        # Create trajectory with high decay, low growth -> anapressive > 1
        traj = _make_trajectory(steps=10, with_events=False)
        for s in traj:
            s["total_M"] = 1000.0  # high M
            s["n_active"] = 8
            s["K_env"] = 1100.0  # close to capacity
            s["affordance_mean"] = 0.1  # low affordance = high suppression
        result = compute_anopression(traj, mu=0.05)  # high mu
        # At least some steps should have anapressive > 1
        anapressive_totals = [
            result["oppression"][t] + result["suppression"][t]
            + result["depression"][t] + result["compression"][t]
            for t in range(len(result["oppression"]))
        ]
        self.assertTrue(any(a > 1.0 for a in anapressive_totals),
                        f"Expected some anapressive > 1.0, got max={max(anapressive_totals):.4f}")


class TestPressureRatio(unittest.TestCase):
    """Tests for pressure ratio (net entropy/extropy indicator)."""

    def test_pressure_ratio_computed(self):
        """Pressure ratio should be sum of anapressive scores."""
        from simulator.taps import compute_anopression, pressure_ratio
        traj = _make_trajectory(steps=10)
        ano = compute_anopression(traj, mu=0.005)
        ratios = pressure_ratio(ano)
        self.assertEqual(len(ratios), len(traj))

    def test_high_pressure_means_entropy(self):
        """Pressure ratio > 1 indicates net entropy."""
        from simulator.taps import compute_anopression, pressure_ratio
        traj = _make_trajectory(steps=10, with_events=False)
        for s in traj:
            s["total_M"] = 1000.0
            s["K_env"] = 1100.0
            s["affordance_mean"] = 0.1
        ano = compute_anopression(traj, mu=0.05)
        ratios = pressure_ratio(ano)
        self.assertTrue(any(r > 1.0 for r in ratios))


class TestRIPDominance(unittest.TestCase):
    """Tests for RIP mode classification."""

    def test_recursion_dominant_no_events(self):
        """Steps with no metathesis events should be recursion-dominant."""
        from simulator.taps import compute_rip
        traj = _make_trajectory(steps=10, with_events=False)
        # Make total_M change so recursion_score > 0
        for i, s in enumerate(traj):
            s["total_M"] = 100.0 + i * 10
        result = compute_rip(traj)
        # All steps should be recursion-dominant (no events)
        for t in range(1, len(result["dominance"])):
            self.assertEqual(result["dominance"][t], "recursion")

    def test_praxis_dominant_with_events(self):
        """Steps with metathesis events should be praxis-dominant."""
        from simulator.taps import compute_rip
        traj = _make_trajectory(steps=10, with_events=True)
        result = compute_rip(traj)
        # Step 3 has events -> should be praxis-dominant
        self.assertEqual(result["dominance"][3], "praxis")


class TestCorrelationMatrix(unittest.TestCase):
    """Tests for correlation analysis."""

    def test_output_shape(self):
        """Correlation matrix should be square with correct dimensions."""
        from simulator.taps import compute_all_scores, correlation_matrix
        traj = _make_trajectory(steps=50)
        scores = compute_all_scores(traj, mu=0.005)
        result = correlation_matrix(scores)
        n = len(result["labels"])
        self.assertEqual(len(result["matrix"]), n)
        for row in result["matrix"]:
            self.assertEqual(len(row), n)

    def test_highly_correlated_detection(self):
        """Should detect pairs with |r| > 0.85."""
        from simulator.taps import correlation_matrix
        # Construct scores with two perfectly correlated series
        import numpy as np
        x = list(np.linspace(0, 1, 50))
        scores = {
            "mode_a": x,
            "mode_b": x,  # identical = r=1.0
            "mode_c": list(np.random.RandomState(42).rand(50)),
        }
        result = correlation_matrix(scores)
        correlated_pairs = [(a, b) for a, b, r in result["highly_correlated"]]
        self.assertIn(("mode_a", "mode_b"), correlated_pairs)


if __name__ == "__main__":
    unittest.main()
```

**Step 2: Run tests to verify they fail**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/test_taps.py -v`
Expected: FAIL (ImportError for simulator.taps)

**Step 3: Implement `simulator/taps.py`**

```python
"""TAPS/RIP diagnostic overlay for metathetic ensemble trajectories.

CLAIM POLICY LABEL: exploratory
Computes Transvolution (T), Anopression/Anapression (A), Praxis (P),
Syntegration (S), and RIP mode scores post-hoc from trajectory data.

TAPS (Transanoprasyn) and RIP (Recursively Iterative Praxis/Preservation)
are an unpublished dynamic dispositional model by the project author.
See docs/plans/2026-02-26-taps-stage1-design.md for full theoretical
framework, formulas, and literature connections.
"""
from __future__ import annotations

import math
from typing import Any

import numpy as np


# Type alias for trajectory data
Trajectory = list[dict[str, Any]]


def _event_deltas(trajectory: Trajectory) -> list[dict[str, int]]:
    """Compute per-step event deltas from cumulative snapshot counters.

    Returns a list of dicts, one per step, with keys: self, absorptive,
    novel, env, disintegration. Step 0 uses the raw cumulative values.
    """
    keys = [
        ("n_self_metatheses", "self"),
        ("n_absorptive_cross", "absorptive"),
        ("n_novel_cross", "novel"),
        ("n_env_transitions", "env"),
        ("n_disintegration_redistributions", "disintegration"),
    ]
    deltas = []
    for i, snap in enumerate(trajectory):
        d = {}
        for snap_key, delta_key in keys:
            curr = snap.get(snap_key, 0)
            prev = trajectory[i - 1].get(snap_key, 0) if i > 0 else 0
            d[delta_key] = curr - prev
        d["total"] = sum(d.values())
        deltas.append(d)
    return deltas


# ---------------------------------------------------------------------------
# T — Transvolution
# ---------------------------------------------------------------------------

def compute_transvolution(trajectory: Trajectory) -> dict[str, list[float]]:
    """Compute involution, evolution, and condensation scores per step.

    Involution = (self + absorptive) / total_events  [inward folding]
    Evolution  = (novel + disintegration + env) / total_events  [outward unfolding]
    Condensation = involution * evolution  [coupled product]
    """
    deltas = _event_deltas(trajectory)
    involution = []
    evolution = []
    condensation = []

    for d in deltas:
        total = max(1, d["total"])
        inv = (d["self"] + d["absorptive"]) / total
        evo = (d["novel"] + d["disintegration"] + d["env"]) / total
        involution.append(inv)
        evolution.append(evo)
        condensation.append(inv * evo)

    return {
        "involution": involution,
        "evolution": evolution,
        "condensation": condensation,
    }


# ---------------------------------------------------------------------------
# A — Anopression / Anapression
# ---------------------------------------------------------------------------

def compute_anopression(
    trajectory: Trajectory,
    mu: float = 0.005,
) -> dict[str, list[float]]:
    """Compute anopressive and anapressive pressure scores per step.

    Anopressive (normalized to sum=1):
      expression  = agents_with_dM>0 / n_active
      impression  = delta_absorptive / total_events
      adpression  = (delta_self + delta_disint) / total_events

    Anapressive (NOT normalized, can exceed 1.0):
      oppression  = 1 - (mean_dM / max_observed_dM)
      suppression = 1 - affordance_mean
      depression  = mu * mean_M / max(eps, |mean_dM|)
      compression = mean_M / K
    """
    deltas = _event_deltas(trajectory)

    # Pre-compute dM series for oppression
    dM_series = []
    for i, snap in enumerate(trajectory):
        if i == 0:
            dM_series.append(0.0)
        else:
            dM_series.append(snap["total_M"] - trajectory[i - 1]["total_M"])

    max_abs_dM = max(abs(dm) for dm in dM_series) if dM_series else 1.0
    if max_abs_dM == 0:
        max_abs_dM = 1.0

    expression = []
    impression = []
    adpression = []
    oppression = []
    suppression = []
    depression = []
    compression = []

    for i, (snap, d) in enumerate(zip(trajectory, deltas)):
        n_active = max(1, snap.get("n_active", 1))
        total_events = max(1, d["total"])
        mean_M = snap["total_M"] / n_active
        dM = dM_series[i]
        K = snap.get("K_env", None)
        aff = snap.get("affordance_mean", 0.0)

        # --- Anopressive (raw, then normalize) ---
        # Expression: fraction of M growing (proxy: dM > 0 at ensemble level)
        expr_raw = 1.0 if dM > 0 else (0.5 if dM == 0 else 0.0)
        # Impression: absorptive events
        impr_raw = d["absorptive"] / total_events if d["total"] > 0 else 0.0
        # Adpression: punctuated events (self-metathesis + disintegration)
        adpr_raw = (d["self"] + d["disintegration"]) / total_events if d["total"] > 0 else 0.0

        ano_total = expr_raw + impr_raw + adpr_raw
        if ano_total > 0:
            expression.append(expr_raw / ano_total)
            impression.append(impr_raw / ano_total)
            adpression.append(adpr_raw / ano_total)
        else:
            expression.append(0.0)
            impression.append(0.0)
            adpression.append(0.0)

        # --- Anapressive (not normalized) ---
        oppression.append(1.0 - (dM / max_abs_dM) if max_abs_dM > 0 else 1.0)
        suppression.append(1.0 - aff)
        eps = 1e-10
        depression.append(mu * mean_M / max(eps, abs(dM)) if abs(dM) > eps else 0.0)
        compression.append(mean_M / K if K and K > 0 else 0.0)

    return {
        "expression": expression,
        "impression": impression,
        "adpression": adpression,
        "oppression": oppression,
        "suppression": suppression,
        "depression": depression,
        "compression": compression,
    }


def pressure_ratio(ano_scores: dict[str, list[float]]) -> list[float]:
    """Compute pressure ratio per step: sum(anapressive) / 1.0.

    > 1.0 = net entropy (breaking exceeds building capacity)
    < 1.0 = net extropy (building exceeds breaking)
    = 1.0 = syntropic equilibrium
    """
    n = len(ano_scores["oppression"])
    ratios = []
    for t in range(n):
        ana_total = (
            ano_scores["oppression"][t]
            + ano_scores["suppression"][t]
            + ano_scores["depression"][t]
            + ano_scores["compression"][t]
        )
        ratios.append(ana_total)
    return ratios


# ---------------------------------------------------------------------------
# P — Praxis
# ---------------------------------------------------------------------------

def compute_praxis(trajectory: Trajectory) -> dict[str, list[float]]:
    """Compute projection, reflection, and action scores per step."""
    deltas = _event_deltas(trajectory)
    projection = [snap.get("innovation_potential", 0.0) for snap in trajectory]
    reflection = [snap.get("affordance_mean", 0.0) for snap in trajectory]
    action = [float(d["total"]) for d in deltas]
    return {"projection": projection, "reflection": reflection, "action": action}


# ---------------------------------------------------------------------------
# S — Syntegration
# ---------------------------------------------------------------------------

def compute_syntegration(trajectory: Trajectory) -> dict[str, list[float]]:
    """Compute disintegration, preservation, integration, synthesis per step."""
    deltas = _event_deltas(trajectory)
    disintegration = [float(d["disintegration"]) for d in deltas]
    preservation = []
    integration = [float(d["absorptive"]) for d in deltas]
    synthesis = [float(d["self"] + d["novel"]) for d in deltas]

    for snap in trajectory:
        n_act = snap.get("n_active", 1)
        n_dor = snap.get("n_dormant", 0)
        total = max(1, n_act + n_dor)
        preservation.append(n_dor / total)

    return {
        "disintegration": disintegration,
        "preservation": preservation,
        "integration": integration,
        "synthesis": synthesis,
    }


# ---------------------------------------------------------------------------
# RIP — Recursion / Iteration / Praxis dominance
# ---------------------------------------------------------------------------

def compute_rip(trajectory: Trajectory) -> dict[str, list]:
    """Compute RIP dominance classification per step.

    Recursion: |dM| when no metathesis events (pure TAP tick).
    Iteration: |affordance change| + |dormancy change| (state accumulation).
    Praxis: total metathesis events (agentic action).
    """
    deltas = _event_deltas(trajectory)
    recursion_scores = []
    iteration_scores = []
    praxis_scores = []
    dominance = []

    for i, (snap, d) in enumerate(zip(trajectory, deltas)):
        # Recursion: TAP tick magnitude (only counts when no events)
        if i == 0:
            dM = 0.0
        else:
            dM = abs(snap["total_M"] - trajectory[i - 1]["total_M"])
        rec = dM if d["total"] == 0 else 0.0

        # Iteration: state accumulation that changes future recursions
        if i == 0:
            d_aff = 0.0
            d_dorm = 0.0
        else:
            d_aff = abs(snap.get("affordance_mean", 0) - trajectory[i - 1].get("affordance_mean", 0))
            d_dorm = abs(snap.get("n_dormant", 0) - trajectory[i - 1].get("n_dormant", 0))
        ite = d_aff + d_dorm

        # Praxis: agentic events
        pra = float(d["total"])

        recursion_scores.append(rec)
        iteration_scores.append(ite)
        praxis_scores.append(pra)

        # Dominance
        scores = {"recursion": rec, "iteration": ite, "praxis": pra}
        dom = max(scores, key=scores.get)
        dominance.append(dom)

    return {
        "recursion": recursion_scores,
        "iteration": iteration_scores,
        "praxis": praxis_scores,
        "dominance": dominance,
    }


# ---------------------------------------------------------------------------
# Aggregate + Correlation
# ---------------------------------------------------------------------------

def compute_all_scores(
    trajectory: Trajectory,
    mu: float = 0.005,
) -> dict[str, list[float]]:
    """Compute all TAPS + RIP mode scores, returning a flat dict of arrays.

    Keys are mode names (involution, evolution, condensation, expression,
    impression, adpression, oppression, suppression, depression, compression,
    projection, reflection, action, disintegration, preservation, integration,
    synthesis). All arrays have length == len(trajectory).
    """
    t_scores = compute_transvolution(trajectory)
    a_scores = compute_anopression(trajectory, mu=mu)
    p_scores = compute_praxis(trajectory)
    s_scores = compute_syntegration(trajectory)

    all_scores = {}
    for d in [t_scores, a_scores, p_scores, s_scores]:
        all_scores.update(d)
    return all_scores


def correlation_matrix(
    scores: dict[str, list[float]],
) -> dict[str, Any]:
    """Compute pairwise Pearson correlation between all mode score series.

    Returns:
        dict with keys:
          matrix: 2D list of r values
          labels: ordered list of mode names
          highly_correlated: list of (mode_a, mode_b, r) where |r| > 0.85
          independent_count: modes with no |r| > 0.85 partner
    """
    labels = sorted(scores.keys())
    n = len(labels)
    data = np.array([scores[label] for label in labels])  # shape (n_modes, n_steps)

    # Handle constant series (std=0) gracefully
    with np.errstate(divide="ignore", invalid="ignore"):
        corr = np.corrcoef(data)
    corr = np.nan_to_num(corr, nan=0.0)

    matrix = corr.tolist()

    highly_correlated = []
    correlated_modes = set()
    for i in range(n):
        for j in range(i + 1, n):
            r = corr[i, j]
            if abs(r) > 0.85:
                highly_correlated.append((labels[i], labels[j], round(float(r), 4)))
                correlated_modes.add(labels[i])
                correlated_modes.add(labels[j])

    independent_count = n - len(correlated_modes)

    return {
        "matrix": matrix,
        "labels": labels,
        "highly_correlated": highly_correlated,
        "independent_count": independent_count,
    }
```

**Step 4: Run tests**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/test_taps.py -v`
Expected: All 12 pass.

**Step 5: Run full suite**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/ -v`
Expected: 188/188 pass (176 + 12 new).

**Step 6: Commit**

```bash
git add simulator/taps.py tests/test_taps.py
git commit -m "feat: add TAPS/RIP diagnostic overlay module

Post-hoc computation of Transvolution (T), Anopression/Anapression (A),
Praxis (P), Syntegration (S), and RIP mode scores from trajectory data.
Includes correlation matrix analysis for mode independence testing.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

### Task 3: TAPS diagnostics script + figures

**Files:**
- Create: `scripts/taps_diagnostics.py`

**Context:**
CLI script that runs a MetatheticEnsemble, computes TAPS overlay, prints summary, generates two figures (correlation heatmap + texture map), and optionally runs gated-vs-ungated comparison.

**Step 1: Write the script**

```python
"""Run metathetic ensemble with TAPS/RIP diagnostic overlay.

CLAIM POLICY LABEL: exploratory
Computes TAPS mode scores post-hoc from trajectory data and generates
diagnostic figures for mode independence analysis.

Produces:
  outputs/figures/taps_correlation.png  — mode correlation heatmap
  outputs/figures/taps_texture.png      — pressure cascade + RIP over time

Usage:
  python scripts/taps_diagnostics.py
  python scripts/taps_diagnostics.py --compare
  python scripts/taps_diagnostics.py --n-agents 15 --steps 200
"""
from __future__ import annotations

import argparse
import json
import os
import sys
from pathlib import Path

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import numpy as np

from simulator.metathetic import MetatheticEnsemble
from simulator.taps import (
    compute_all_scores,
    compute_anopression,
    compute_rip,
    correlation_matrix,
    pressure_ratio,
)

ROOT = Path(__file__).resolve().parents[1]
FIG_OUT = ROOT / "outputs" / "figures"


def run_ensemble(
    n_agents: int = 10,
    steps: int = 150,
    alpha: float = 5e-3,
    a: float = 3.0,
    mu: float = 0.005,
    variant: str = "logistic",
    seed: int = 42,
    affordance_min_cluster: int = 2,
    skip_disintegration: bool = False,
) -> tuple[list[dict], MetatheticEnsemble]:
    """Run ensemble and return trajectory + ensemble object."""
    ens = MetatheticEnsemble(
        n_agents=n_agents,
        initial_M=10.0,
        alpha=alpha, a=a, mu=mu,
        variant=variant,
        carrying_capacity=2e5 if variant == "logistic" else None,
        seed=seed,
        affordance_min_cluster=affordance_min_cluster,
    )
    trajectory = ens.run(steps=steps)
    return trajectory, ens


def fig_correlation(scores: dict, save_path: Path) -> None:
    """Correlation heatmap of TAPS mode scores."""
    plt.rcParams.update({
        "font.size": 9, "savefig.dpi": 300, "savefig.bbox": "tight",
    })

    result = correlation_matrix(scores)
    labels = result["labels"]
    matrix = np.array(result["matrix"])
    n = len(labels)

    fig, ax = plt.subplots(figsize=(10, 8))
    im = ax.imshow(matrix, cmap="RdBu_r", vmin=-1, vmax=1, aspect="auto")

    ax.set_xticks(range(n))
    ax.set_yticks(range(n))
    ax.set_xticklabels(labels, rotation=45, ha="right", fontsize=7)
    ax.set_yticklabels(labels, fontsize=7)

    # Annotate cells
    for i in range(n):
        for j in range(n):
            val = matrix[i, j]
            color = "white" if abs(val) > 0.6 else "black"
            ax.text(j, i, f"{val:.2f}", ha="center", va="center",
                    fontsize=6, color=color)

    plt.colorbar(im, ax=ax, label="Pearson r")
    ax.set_title("TAPS Mode Correlation Matrix  [exploratory]")

    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(str(save_path))
    plt.close(fig)
    print(f"Wrote {save_path}")


def fig_texture(
    trajectory: list[dict],
    ano_scores: dict,
    rip_result: dict,
    corr_result: dict,
    save_path: Path,
) -> None:
    """Pressure cascade texture map + RIP dominance band."""
    plt.rcParams.update({
        "font.size": 9, "savefig.dpi": 300, "savefig.bbox": "tight",
    })

    steps = [s["step"] for s in trajectory]
    n = len(steps)

    # Build synchronous mode pairs for hatching (|r| > 0.7)
    sync_pairs = set()
    for a, b, r in corr_result.get("highly_correlated", []):
        if abs(r) > 0.7:
            sync_pairs.add((a, b))
            sync_pairs.add((b, a))

    fig, (ax_main, ax_pressure, ax_rip) = plt.subplots(
        3, 1, figsize=(12, 8),
        gridspec_kw={"height_ratios": [6, 1, 1]},
        sharex=True,
    )

    # --- Top panel: Stacked pressure cascade ---
    # Anapressive (warm, bottom): oppression -> suppression -> depression -> compression
    ana_layers = ["oppression", "suppression", "depression", "compression"]
    ana_colors = ["#D32F2F", "#E64A19", "#F57C00", "#FFA726"]
    # Anopressive (cool, top): adpression -> impression -> expression
    ano_layers = ["adpression", "impression", "expression"]
    ano_colors = ["#00897B", "#0288D1", "#1565C0"]

    all_layers = ana_layers + ano_layers
    all_colors = ana_colors + ano_colors

    # Stack arrays
    y_stack = np.zeros(n)
    for layer_name, color in zip(all_layers, all_colors):
        y_values = np.array(ano_scores[layer_name])
        hatch = ""
        # Check if this layer is synchronous with any other
        for other in all_layers:
            if other != layer_name and (layer_name, other) in sync_pairs:
                hatch = "//"
                break
        ax_main.fill_between(steps, y_stack, y_stack + y_values,
                             color=color, alpha=0.8, label=layer_name,
                             hatch=hatch, edgecolor="white", linewidth=0.3)
        y_stack = y_stack + y_values

    ax_main.set_ylabel("Pressure Score (stacked)")
    ax_main.set_title("TAPS Pressure Cascade Over Time  [exploratory]")
    ax_main.legend(loc="upper right", fontsize=7, ncol=2)

    # --- Middle band: Pressure spectrum (mode dominance widths) ---
    # For each step, show the dominant mode as proportional width
    mode_names = all_layers
    mode_colors_map = dict(zip(all_layers, all_colors))
    for t_idx in range(n):
        mode_vals = {m: ano_scores[m][t_idx] for m in mode_names}
        total = sum(mode_vals.values())
        if total == 0:
            continue
        y_bottom = 0.0
        for m in mode_names:
            frac = mode_vals[m] / total
            hatch = ""
            for other in mode_names:
                if other != m and (m, other) in sync_pairs:
                    hatch = "//"
                    break
            ax_pressure.bar(steps[t_idx], frac, bottom=y_bottom, width=1.0,
                            color=mode_colors_map[m], hatch=hatch,
                            edgecolor="none")
            y_bottom += frac
    ax_pressure.set_ylabel("Mode", fontsize=7)
    ax_pressure.set_ylim(0, 1)
    ax_pressure.set_yticks([])

    # --- Bottom band: RIP dominance ---
    rip_colors = {"recursion": "#9E9E9E", "iteration": "#42A5F5", "praxis": "#EF5350"}
    for t_idx in range(n):
        dom = rip_result["dominance"][t_idx]
        ax_rip.bar(steps[t_idx], 1.0, width=1.0,
                   color=rip_colors.get(dom, "#9E9E9E"), edgecolor="none")
    ax_rip.set_ylabel("RIP", fontsize=7)
    ax_rip.set_xlabel("Step")
    ax_rip.set_ylim(0, 1)
    ax_rip.set_yticks([])

    # RIP legend
    from matplotlib.patches import Patch
    rip_patches = [Patch(color=c, label=l) for l, c in rip_colors.items()]
    ax_rip.legend(handles=rip_patches, loc="upper right", fontsize=7, ncol=3)

    plt.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(str(save_path))
    plt.close(fig)
    print(f"Wrote {save_path}")


def print_summary(scores: dict, ratios: list[float], rip: dict, corr: dict) -> None:
    """Print TAPS diagnostic summary to console."""
    n = len(ratios)
    last = n - 1

    print("\n  TAPS Diagnostic Summary:")
    print(f"  {'='*50}")

    # Pressure ratio
    pr_final = ratios[last]
    pr_label = "entropy" if pr_final > 1.0 else ("extropy" if pr_final < 1.0 else "equilibrium")
    print(f"  Pressure ratio:   {pr_final:.4f} (net {pr_label})")

    # Mode scores at final step
    print(f"\n  Anopressive (normalized):")
    print(f"    Expression:     {scores['expression'][last]:.4f}")
    print(f"    Impression:     {scores['impression'][last]:.4f}")
    print(f"    Adpression:     {scores['adpression'][last]:.4f}")
    print(f"  Anapressive (raw):")
    print(f"    Oppression:     {scores['oppression'][last]:.4f}")
    print(f"    Suppression:    {scores['suppression'][last]:.4f}")
    print(f"    Depression:     {scores['depression'][last]:.4f}")
    print(f"    Compression:    {scores['compression'][last]:.4f}")

    # Transvolution
    print(f"\n  Transvolution:")
    print(f"    Involution:     {scores['involution'][last]:.4f}")
    print(f"    Evolution:      {scores['evolution'][last]:.4f}")
    print(f"    Condensation:   {scores['condensation'][last]:.4f}")

    # RIP
    rip_counts = {"recursion": 0, "iteration": 0, "praxis": 0}
    for d in rip["dominance"]:
        rip_counts[d] = rip_counts.get(d, 0) + 1
    print(f"\n  RIP dominance counts:")
    for mode, count in rip_counts.items():
        print(f"    {mode:12s}:   {count}/{n} steps ({100*count/n:.1f}%)")

    # Correlation
    print(f"\n  Mode independence:")
    print(f"    Independent modes: {corr['independent_count']}/{len(corr['labels'])}")
    if corr["highly_correlated"]:
        print(f"    Correlated pairs:")
        for a, b, r in corr["highly_correlated"]:
            print(f"      {a} <-> {b}: r={r:.4f}")

    print(f"\n  [exploratory — see CLAIM_POLICY.md]")


def main() -> None:
    parser = argparse.ArgumentParser(description="TAPS/RIP diagnostic overlay")
    parser.add_argument("--n-agents", type=int, default=10)
    parser.add_argument("--steps", type=int, default=150)
    parser.add_argument("--alpha", type=float, default=5e-3)
    parser.add_argument("--a", type=float, default=3.0)
    parser.add_argument("--mu", type=float, default=0.005)
    parser.add_argument("--variant", type=str, default="logistic")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--compare", action="store_true",
                        help="Run gated vs ungated comparison")
    args = parser.parse_args()

    print(f"Running TAPS diagnostics: {args.n_agents} agents, {args.steps} steps")
    trajectory, ens = run_ensemble(
        n_agents=args.n_agents, steps=args.steps,
        alpha=args.alpha, a=args.a, mu=args.mu,
        variant=args.variant, seed=args.seed,
    )

    # Compute all TAPS scores
    scores = compute_all_scores(trajectory, mu=args.mu)
    ano_scores = compute_anopression(trajectory, mu=args.mu)
    ratios = pressure_ratio(ano_scores)
    rip = compute_rip(trajectory)
    corr = correlation_matrix(scores)

    # Print summary
    print_summary(scores, ratios, rip, corr)

    # Generate figures
    fig_correlation(scores, FIG_OUT / "taps_correlation.png")
    fig_texture(trajectory, ano_scores, rip, corr, FIG_OUT / "taps_texture.png")

    # Optional: gated vs ungated comparison
    if args.compare:
        print(f"\n  {'='*50}")
        print(f"  Gated vs Ungated Comparison (same seed={args.seed}):")
        print(f"  {'='*50}")

        traj_ungated, _ = run_ensemble(
            n_agents=args.n_agents, steps=args.steps,
            alpha=args.alpha, a=args.a, mu=args.mu,
            variant=args.variant, seed=args.seed,
            affordance_min_cluster=0,  # disable gate
        )
        scores_ungated = compute_all_scores(traj_ungated, mu=args.mu)
        ano_ungated = compute_anopression(traj_ungated, mu=args.mu)
        ratios_ungated = pressure_ratio(ano_ungated)

        last_g = len(ratios) - 1
        last_u = len(ratios_ungated) - 1
        print(f"\n  {'Metric':<25s} {'Gated':>10s} {'Ungated':>10s}")
        print(f"  {'-'*47}")
        print(f"  {'Pressure ratio':<25s} {ratios[last_g]:>10.4f} {ratios_ungated[last_u]:>10.4f}")
        print(f"  {'Involution':<25s} {scores['involution'][last_g]:>10.4f} {scores_ungated['involution'][last_u]:>10.4f}")
        print(f"  {'Evolution':<25s} {scores['evolution'][last_g]:>10.4f} {scores_ungated['evolution'][last_u]:>10.4f}")
        print(f"  {'Condensation':<25s} {scores['condensation'][last_g]:>10.4f} {scores_ungated['condensation'][last_u]:>10.4f}")
        print(f"  {'Preservation':<25s} {scores['preservation'][last_g]:>10.4f} {scores_ungated['preservation'][last_u]:>10.4f}")

        # Final trajectory metrics
        g_last = trajectory[-1]
        u_last = traj_ungated[-1]
        print(f"\n  {'D_total':<25s} {g_last['D_total']:>10d} {u_last['D_total']:>10d}")
        print(f"  {'k_total':<25s} {g_last['k_total']:>10.1f} {u_last['k_total']:>10.1f}")
        print(f"  {'n_self_metatheses':<25s} {g_last['n_self_metatheses']:>10d} {u_last['n_self_metatheses']:>10d}")
        print(f"  {'n_disinteg_redist':<25s} {g_last['n_disintegration_redistributions']:>10d} {u_last['n_disintegration_redistributions']:>10d}")

    print("\nDone.")


if __name__ == "__main__":
    main()
```

**Step 2: Run the script to verify it works**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" scripts/taps_diagnostics.py`
Expected: Prints TAPS summary, writes two PNGs.

Run with compare: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" scripts/taps_diagnostics.py --compare`
Expected: Also prints gated vs ungated comparison table.

**Step 3: Run full test suite**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/ -v`
Expected: 188/188 pass.

**Step 4: Commit**

```bash
git add scripts/taps_diagnostics.py
git commit -m "feat: add TAPS diagnostics script with correlation + texture figures

CLI script that runs ensemble, computes TAPS/RIP overlay, prints summary,
generates correlation heatmap and pressure cascade texture map. Supports
--compare flag for gated vs ungated run comparison.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

### Task 4: TAPS mapping document

**Files:**
- Create: `docs/taps_mapping.md`

**Context:**
Complete reference document mapping every TAPS/RIP mode to its TAP observable and formula. Includes the Emery & Trist L-mapping bridge, literature citations, and project author attribution. This is the permanent reference for the TAPS framework in this codebase.

**Step 1: Write the document**

This document should contain:

1. **Header** with exploratory label and attribution
2. **Mode-to-Observable Table**: each of the 17 mode scores mapped to its snapshot field(s) and formula
3. **Cascade Ordering**: the full pressure cascade from expression (ano apex) through the fulcrum to oppression (ana base)
4. **Emery & Trist L-mapping**: L11=athetic, L12=thetic, L21=synthetic, L22=metathetic
5. **Dialectical Foundation**: thesis/athesis/synthesis/metathesis definitions
6. **Synchronic/Diachronic**: TAP tick = synchronic, events = diachronic
7. **Conservation Principles**: expression=1, syntropy primary, minimal praxis to maximal syntegration
8. **Literature References**: Odling-Smee (2003), Frankham (2014), Marshall (1890), Krugman (1991), Longo/Montevil/Kauffman (2012), Bohm (1980), Emery & Trist (1965), Emery (1977)
9. **Attribution**: TAPS, RIP, metathesis extension, Laws of Adjacency and Inclusion are the project author's unpublished original work

**Step 2: Commit**

```bash
git add docs/taps_mapping.md
git commit -m "docs: add TAPS/RIP mode-to-observable mapping document

Complete reference mapping 17 TAPS/RIP modes to TAP observables with
formulas, cascade ordering, Emery & Trist bridge, dialectical foundation,
conservation principles, literature citations, and attribution.

Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>"
```

---

### Task 5: Final verification + push

**Step 1: Run full test suite**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" -m pytest tests/ -v`
Expected: 188/188 pass.

**Step 2: Run TAPS diagnostics standalone**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" scripts/taps_diagnostics.py --compare`
Expected: Prints summary + comparison, writes 2 PNGs.

**Step 3: Run claim audit**

Run: `"C:\Users\user\AppData\Local\Programs\Python\Python312\python.exe" scripts/audit_claims.py`
Expected: PASSED.

**Step 4: Push**

```bash
git push origin unified-integration-20260225
```
